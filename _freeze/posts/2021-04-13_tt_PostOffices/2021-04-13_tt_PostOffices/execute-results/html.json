{
  "hash": "5a88e33b073bcd8d8c16f7f6cd61cacc",
  "result": {
    "markdown": "---\ntitle: \"Tidy Tuesday: U.S. Post Offices\"\ndate: \"2021-04-27\"\ncategories: [DataViz]\n---\n\n::: {.cell}\n\n:::\n\nMy data visualization based on a dataset of US Post Offices for 166,140 post offices that operated in the United States between 1639 and 2000.\n\nA quick analysis of the weekly [\\#TidyTuesday](http://github.com/rfordatascience/tidytuesday) dataset organized by the R4DS Online Learning Community. My approach is to apply my data science skills to explore one question I have about the data and generate a visualization that addresses this question. The main purpose for me is to practice and try out new things. I am never completely satisfied with the end result but I do the best I can in a short period of time.\n\n**What I learned this week about R and the Tidyverse**\n\n-   Creating a stacked area chart using ```geom_area``` function in ```ggplot2```\n-   Slight adjustments in placing the axis title using the ```margin``` function in the plot theme\n\n**Brief explanation of the dataset**\n\nThis dataset is from [DataIsPlural](https://www.data-is-plural.com/archive/2021-04-21-edition/) and contains reasons for CEO departures from S&P 1500 firms. Information is provided about the company name, CEO name and date of departure along with notes and links to articles which were used to assign the departure reason.  Reasons were assigned to one of 9 different codes.  Codes 1-4 were involuntary reasons such as CEO died or was ill and CEO was terminated for poor job performance or legal issues. Codes 5-6 were voluntary reasons such as the CEO retired or decided to leave for a new opportunity.  Code 7 is mostly about a change following a merger or acquisition and in some cases the CEO stayed on with the new company.  Code 8-9 are missing or data collection error.\n\n### Load libraries and data\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nlibrary(geojsonio)\nlibrary(rgdal)\nlibrary(broom)\nlibrary(rgeos)\n\nlibrary(viridis)\nlibrary(showtext)\n\nfont_add_google(name = \"Oswald\")\n\ntheme_set(theme_minimal())\n\n#Load dataset from TidyTuesday repository\npost_offices <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-13/post_offices.csv')\nus_reps <- read_csv(file = \"../data/us_reps_state.csv\") %>% janitor::clean_names()\n```\n:::\n\n### Wrangle\n\nInitial conclusions from exploring the post_offices dataset.  \n\n* The established date for post offices ranged from 1877-2000.  \n* The discontinued date can be missing and would suggest the post office is still in operation as of 2000.  \n* The state and county is available for almost all of the post offices.\n* The GNIS information including latitude and longitude is present for about 2/3 of the data.  \n\nThe assumption is that the missing (NA) discontinued year means the post office is still operating.  Based on this assumption, we calculate the number of post offices per state and as a ratio to the number of US House of Representatives for each state.\n\n\n::: {.cell}\n\n```{.r .cell-code}\noffice_count <- post_offices %>%\n  select(id, name, state, established, discontinued) %>%\n  filter(is.na(discontinued)) %>%\n  group_by(state) %>%\n  summarize(offices = n(), .groups = \"drop\")\n\noffice_ratio <- us_reps %>%\n  left_join(tibble(state = state.name, id = state.abb), by = \"state\") %>%\n  left_join(office_count, by = c(\"id\" =  \"state\")) %>%\n  mutate(rep_ratio = offices / representatives_number,\n         pop_ratio = pop / offices) %>%\n  arrange(desc(pop_ratio))\n```\n:::\n\n\n### Visualize\n\nLet's first look at the states with the most number of post offices.\n\n::: {.cell}\n\n```{.r .cell-code}\noffice_count %>%\n  arrange(desc(offices)) %>%\n  slice(1:10) %>%\n  mutate(state = fct_reorder(state, offices)) %>%\n  ggplot(aes(x = offices, y = state)) +\n  geom_col(fill = \"steelblue\") +\n  labs(title = \"Top 10 States with the Highest Number of Post Offices\",\n       x = \"# of Post Offices\",\n       y = NULL)\n```\n\n::: {.cell-output-display}\n![](2021-04-13_tt_PostOffices_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\nNow let's look at the ratio of post offices per US representatives for each state.\n\n::: {.cell}\n\n```{.r .cell-code}\noffice_ratio %>%\n  arrange(desc(rep_ratio)) %>%\n  slice(1:10) %>%\n  mutate(state = fct_reorder(state, rep_ratio)) %>%\n  ggplot(aes(x = rep_ratio, y = state)) +\n  geom_col(fill = \"midnightblue\") +\n  labs(title = \"Top 10 States with the Highest Number of Post Offices per US Rep\",\n       x = \"# of Post Offices\",\n       y = NULL)\n```\n\n::: {.cell-output-display}\n![](2021-04-13_tt_PostOffices_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\nThe most post offices per state generally includes the most populous states while the most post offices per US representatives includes some of the less populous states.  Kentucky and Iowa show up in both top ten lists.  I decided from here that I was most interested in the average population served by the post offices in each state.  I wanted to create a map but not using the US map but rather a hexbin representation I had come across previously.\n\nCreating the hexbin map was more complicated than I thought it would be when I began.  The first step was to download a geojson file which I found [here](https://team.carto.com/u/andrew/tables/andrew.us_states_hexgrid/public/map).  This file contained the boundaries for the hexagons for each state.  The file is read using the ```geojsonio``` package into a ```SpatialPolygonsDataFrame``` class.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#geojsonio package\nspdf <- geojson_read(\"../data/us_states_hexgrid.geojson\",  what = \"sp\")\n\n#reformat the state name\nspdf@data = spdf@data %>%\n  mutate(google_name = gsub(\" \\\\(United States\\\\)\", \"\", google_name))\n\n# Show it (requires rgdal library)\nplot(spdf)\n```\n\n::: {.cell-output-display}\n![](2021-04-13_tt_PostOffices_files/figure-html/Visualize-1.png){width=672}\n:::\n:::\n\nWe can then reformat the spdf data into a standard data frame using the ```tidy``` function from the ```broom``` package.  Next, we need to calculate the center of each hexagon for adding the label with the state abbreviation.  The centroid is calculated from the spdf data using a function from the ```rgeos``` package.\n\n::: {.cell}\n\n```{.r .cell-code}\n# reformat as data frame for ggplot\nspdf_fortified <- tidy(spdf, region = \"iso3166_2\")\n\n#calculate centroid of each hexagon for adding label\ncenters <- cbind.data.frame(data.frame(gCentroid(spdf, byid=TRUE), id=spdf@data$iso3166_2))\n\nggplot() +\n  geom_polygon(data = spdf_fortified, aes( x = long, y = lat, group = group), fill=\"skyblue\", color=\"white\") +\n  geom_text(data=centers, aes(x=x, y=y, label=id)) +\n  theme_void() +\n  coord_map()\n```\n\n::: {.cell-output-display}\n![](2021-04-13_tt_PostOffices_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\nNext, we add the ratio of state population to number of post offices and segregate into bins.\n\n::: {.cell}\n\n```{.r .cell-code}\nspdf_fortified <- spdf_fortified %>%\n  left_join(select(office_ratio, id, pop_ratio), by = \"id\") %>%\n  filter(!is.na(pop_ratio))\n\nspdf_fortified$bin <- cut( spdf_fortified$pop_ratio , breaks=c(seq(0, 20000, 5000), Inf), \n                           labels=c(\"< 5K\", \"5-10K\", \"10-15K\", \"15-20K\", \"20K+\") , include.lowest = TRUE )\n```\n:::\n\n\nFinally, we create the hexbin map with the post office data.\n\n::: {.cell}\n\n```{.r .cell-code}\nshowtext_auto()\nmy_palette <- rev(magma(8))[c(-1,-8)]\n\np1 <- ggplot() +\n  geom_polygon(data = spdf_fortified, aes(fill = bin, x = long, y = lat, group = group) , size=0, alpha=0.9) +\n  geom_text(data=centers, aes(x=x, y=y, label=id), color=\"white\", size=3, alpha=0.6) +\n  theme_void() +\n  scale_fill_manual( \n    values=my_palette, \n    name=\"Average population served per post office\", \n    guide = guide_legend( keyheight = unit(3, units = \"mm\"), keywidth=unit(12, units = \"mm\"), label.position = \"bottom\", title.position = 'top', nrow=1) \n  ) +\n  labs( title = \"Population Served per Post Office ca. 2000\",\n        caption = \"Graphic: @datadavidz | Source: Blevins and Helbock | #TidyTuesday\") +\n  theme(\n    legend.position = c(0.5, 0.9),\n    text = element_text(color = \"#22211d\"),\n    plot.background = element_rect(fill = \"#f5f5f2\", color = NA), \n    panel.background = element_rect(fill = \"#f5f5f2\", color = NA), \n    legend.background = element_rect(fill = \"#f5f5f2\", color = NA),\n    plot.title = element_text(family = \"Oswald\", size= 22, hjust=0.5, color = \"#4e4d47\", margin = margin(b = -0.1, t = 0.4, l = 2, unit = \"cm\")),\n    plot.caption = element_text(hjust = 0.95, vjust = 1)\n  )\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n![Data Visualization for U.S. Post Offices](PostOffices.png){.preview-image}\n### Summary\n\nI felt this hexbin map was an effective and aesthetically-pleasing graphic for the analysis.  The construction of the hexbin map was more complex than I imagined requiring a website download, multiple packages I don't normally use and new data formats.  I have seen people make similar plots using the ```geofacet``` package and I am interested whether this could simplify the process.  However, this package doesn't appear to be able to easily make the hexagon shapes.\n",
    "supporting": [
      "2021-04-13_tt_PostOffices_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}