{
  "hash": "cc9d719a8569a4f8f4f069e0a3ce09fa",
  "result": {
    "markdown": "---\ntitle: \"Pin a Vetiver Model to an AWS S3 Container\"\ndate: \"2022-10-14\"\ncategories: [tidymodels, MLOps]\n---\n\n::: {.cell}\n\n:::\n\n\nAn XGBoost model for predicting concrete strength is transformed into a deployable model object and store it in an AWS S3 container.\n\nIn this post, I will take the XGBoost model for predicting concrete compressive strength described in a previous [post](https://datadavidz.github.io/posts/2022-09-24_ConcreteXGB/2022-09-24_ConcreteXGB.html), convert the model into a deployable model object using ```vetiver```and \"pin\" it to an S3 bucket.  The purpose of this effort is to make the model accessible in the cloud to an API running in a different location.  The development of the API will be discussed in the next post.  S3 stands for the AWS Simple Storage Service which exists in the cloud.  I chose AWS over other ```vetiver```-compatible options simply because I already had an existing account.   \n\n## Build the model (again)\nThis section just performs the steps to build the XGBoost model described in detail in the previous post.\n\nLoad the libraries.\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\nlibrary(tidyverse)\n\n#Tidymodels\nlibrary(tidymodels)\nlibrary(xgboost)\n\n#MLOps\nlibrary(vetiver)\nlibrary(pins)\n```\n:::\n\n\nLoad the dataset.\n\n::: {.cell}\n\n```{.r .cell-code}\nfilename <- \"Concrete_Data.xls\"\n\nfolder <- \"../data/\"\nnumberCols <- 9 #total number of columns in spreadsheet\n\ncolTypes <- rep(\"numeric\", numberCols)\nconcrete_tbl <- read_excel(path = paste0(folder, filename), col_types = colTypes)\n\nconcrete_tbl <- concrete_tbl %>%\n  rename(cement = starts_with(\"Cement\")) %>%\n  rename(blast_furnace_slag = starts_with(\"Blast\")) %>%\n  rename(fly_ash = starts_with(\"Fly Ash\")) %>%\n  rename(water = starts_with(\"Water\")) %>%\n  rename(superplasticizer = starts_with(\"Super\")) %>%\n  rename(coarse_aggregate = starts_with(\"Coarse\")) %>%\n  rename(fine_aggregate = starts_with(\"Fine\")) %>%\n  rename(age = starts_with(\"Age\")) %>%\n  rename(compressive_strength = starts_with(\"Concrete\"))\n```\n:::\n\n\nSplit the data into training and testing datasets.\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nconcrete_split <- initial_split(concrete_tbl, prop = 0.80)\nconcrete_train <- training(concrete_split)\nconcrete_test <- testing(concrete_split)\n```\n:::\n\n\nCreate the model recipe.\n\n::: {.cell}\n\n```{.r .cell-code}\nconcrete_rec <- recipe(compressive_strength ~ ., data = concrete_train) %>%\n  step_normalize(all_predictors())\n  \nconcrete_rec\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor          8\n\nOperations:\n\nCentering and scaling for all_predictors()\n```\n:::\n:::\n\nCreate the model specification. Parameters were specified from tuning in previous post.\n\n::: {.cell}\n\n```{.r .cell-code}\nxgboost_spec = boost_tree(\n  trees = 1000,\n  min_n = 18,\n  tree_depth = 10,\n  learn_rate = 0.02647525\n) %>%\n  set_engine(\"xgboost\") %>%\n  set_mode(\"regression\")\n\nxgboost_spec\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBoosted Tree Model Specification (regression)\n\nMain Arguments:\n  trees = 1000\n  min_n = 18\n  tree_depth = 10\n  learn_rate = 0.02647525\n\nComputational engine: xgboost \n```\n:::\n:::\n\nCreate the modeling workflow.\n\n::: {.cell}\n\n```{.r .cell-code}\nconcrete_wf <- workflow() %>%\n  add_recipe(concrete_rec) %>%\n  add_model(xgboost_spec)\n```\n:::\n\n\nFit model on train and evaluate on test.\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_res <- last_fit(concrete_wf, concrete_split, metrics = metric_set(rmse, rsq, mae))\n```\n:::\n\n\nAssess final model performance metrics.\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(final_res)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard       4.33  Preprocessor1_Model1\n2 rsq     standard       0.945 Preprocessor1_Model1\n3 mae     standard       2.69  Preprocessor1_Model1\n```\n:::\n:::\n\n\n## Create the Deployable Model Object\n\nThe deployable model object is created using the ```vetiver``` package.  It is really as simple as extracting the workflow and passing it to the ```vetiver_model``` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nv <- final_res %>%\n  extract_workflow() %>%\n  vetiver_model(model_name = \"concrete-xgb\")\n\nv\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n── concrete-xgb ─ <bundled_workflow> model for deployment \nA xgboost regression modeling workflow using 8 features\n```\n:::\n:::\n\n## Pins and AWS s3\n\nThe ```pins``` package allows you to save data, models or R objects to the cloud such as an AWS S3 container.  A new S3 container can be set up within AWS.  In my case, I just used the default settings with the name ```pins-test-zoller```.  A security id and access key needs to be set up to enable saving of data from your local computer to the S3 container.  In your AWS account options under Security Credentials, you can configure your security id and access key and save the file to your local computer.  There are multiple options to tell R where to find this information but I preferred to create a shared AWS credentials file in a text editor as follows:\n\n```\n[default]\naws_access_key_id=your AWS access key\naws_secret_access_key=your AWS secret key\n```\n\nOn a Windows computer, the file needs to be saved with the name ```credentials``` without any extension.  The file location needs to be ```C:\\Users\\[your username]\\.aws\\```.  You may need to create the ```.aws``` directory.\n\nYou can then connect to the board where you want to place the pin using ```board_s3``` command.  Here, we pin the vetiver model for the concrete data.\n\n::: {.cell}\n\n```{.r .cell-code}\nboard <- board_s3(\"pins-test-zoller\", region = \"us-east-2\")\nboard %>% vetiver_pin_write(v)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nCreating new version '20221017T213232Z-5eb32'\nWriting to pin 'concrete-xgb'\n\nCreate a Model Card for your published model\n• Model Cards provide a framework for transparent, responsible reporting\n• Use the vetiver `.Rmd` template as a place to start\n```\n:::\n:::\n\nIn the AWS S3 bucket with the name \"pins-test-zoller\", a new folder is created with the same name as the model, concrete-xgb.  Within this folder, there is a subfolder with the named according to the model version number and, within the subfolder, is the model object in rds form (concrete-xgb.rds) and a data.txt file with brief information about the model object.\n\n## Summary\n\nAn XGBoost model for the concrete dataset has been converted to a deployable model object using the ```vetiver``` package and then uploaded (i.e. pinned) to an AWS S3 bucket.  The model object can now be accessed in the cloud for different purposes including creating an API to provide model predictions.  The API use case will be discussed further in the next post.\n\n:::{.callout-tip collapse=\"true\"}\n## Expand for Session Info\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.2.0 (2022-04-22 ucrt)\n os       Windows 10 x64 (build 19043)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_United States.utf8\n ctype    English_United States.utf8\n tz       America/Chicago\n date     2022-10-17\n pandoc   2.18 @ C:/Program Files/RStudio/bin/quarto/bin/tools/ (via rmarkdown)\n quarto   1.0.36 @ C:\\\\PROGRA~1\\\\RStudio\\\\bin\\\\quarto\\\\bin\\\\quarto.cmd\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package      * version date (UTC) lib source\n P broom        * 1.0.1   2022-08-29 [?] CRAN (R 4.2.1)\n P dials        * 1.0.0   2022-06-14 [?] CRAN (R 4.2.1)\n P dplyr        * 1.0.10  2022-09-01 [?] CRAN (R 4.2.0)\n P forcats      * 0.5.2   2022-08-19 [?] CRAN (R 4.2.1)\n P ggplot2      * 3.3.6   2022-05-03 [?] CRAN (R 4.2.1)\n P infer        * 1.0.3   2022-08-22 [?] CRAN (R 4.2.1)\n P modeldata    * 1.0.0   2022-07-01 [?] CRAN (R 4.2.1)\n P parsnip      * 1.0.0   2022-06-16 [?] CRAN (R 4.2.1)\n P pins         * 1.0.3   2022-09-24 [?] CRAN (R 4.2.1)\n P purrr        * 0.3.4   2020-04-17 [?] CRAN (R 4.2.1)\n P readr        * 2.1.2   2022-01-30 [?] CRAN (R 4.2.1)\n P readxl       * 1.4.1   2022-08-17 [?] CRAN (R 4.2.1)\n P recipes      * 1.0.1   2022-07-07 [?] CRAN (R 4.2.1)\n P rsample      * 1.0.0   2022-06-24 [?] CRAN (R 4.2.1)\n P scales       * 1.2.1   2022-08-20 [?] CRAN (R 4.2.1)\n P sessioninfo  * 1.2.2   2021-12-06 [?] CRAN (R 4.2.1)\n P stringr      * 1.4.1   2022-08-20 [?] CRAN (R 4.2.1)\n P tibble       * 3.1.8   2022-07-22 [?] CRAN (R 4.2.1)\n P tidymodels   * 1.0.0   2022-07-13 [?] CRAN (R 4.2.1)\n P tidyr        * 1.2.0   2022-02-01 [?] CRAN (R 4.2.1)\n P tidyverse    * 1.3.2   2022-07-18 [?] CRAN (R 4.2.1)\n P tune         * 1.0.0   2022-07-07 [?] CRAN (R 4.2.1)\n P vetiver      * 0.1.8   2022-09-29 [?] CRAN (R 4.2.1)\n P workflows    * 1.0.0   2022-07-05 [?] CRAN (R 4.2.1)\n P workflowsets * 1.0.0   2022-07-12 [?] CRAN (R 4.2.1)\n P xgboost      * 1.6.0.1 2022-04-16 [?] CRAN (R 4.2.1)\n P yardstick    * 1.0.0   2022-06-06 [?] CRAN (R 4.2.1)\n\n [1] C:/Users/David Zoller/AppData/Local/Temp/Rtmp6r699v/renv-library-198833416b74\n [2] C:/Users/David Zoller/Documents/datadavidz.github.io/renv/library/R-4.2/x86_64-w64-mingw32\n [3] C:/Program Files/R/R-4.2.0/library\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────\n```\n:::\n:::\n\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}