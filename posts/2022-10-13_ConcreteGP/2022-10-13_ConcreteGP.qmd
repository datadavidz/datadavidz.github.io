---
title: "Gaussian Process Model for the Concrete Dataset"
date: "2022-10-13"
categories: [sci-kit, reticulate]
---
```{r}
#| echo: false
#| results: "hide"
renv::use(lockfile = "renv.lock")
```

A GP model to predict the compressive strength of concrete is built using R and Python.

This post shares my first analysis of the Concrete [dataset](http://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength) using a Gaussian Process modeling approach.  I was interested in Gaussian Process models due to the possibility of building a non-linear regression model which fits the dataset well and allows for predictions on new data along with the uncertainty in that prediction.  I have previously analyzed this dataset using a variety of machine learning approaches which allows for a good comparison in prediction performance.

The analysis combines R and Python as I wanted to reuse some of the data cleaning from the previous analyses written in R while the Gaussian Process model was built using Python.  The most relevant articles I could find on Gaussian Process modeling contained examples in Python so I decided to use a similar approach.  In this post, I am using the ```GaussianProcessRegressor``` model in the Sci-Kit Learn package to build the model.  An RStudio [blog](https://blogs.rstudio.com/ai/posts/2019-12-10-variational-gaussian-process/) was written in 2019 in R using ```tfprobability``` package on the same dataset but, honestly, I found it difficult to follow and the modeling results (MSE) was higher than my sklearn model.

### Load the R libraries and data

Here I am reusing the code from previous analyses on the Concrete dataset.  The column names needed to be renamed so that they are more manageable for further data manipulations.

```{r, include = FALSE}
#| message: false
#| warning: false
library(tidyverse)
library(readxl)
library(reticulate)
```

```{r}
filename <- "Concrete_Data.xls"

folder <- "../data/"
numberCols <- 9 #total number of columns in spreadsheet

colTypes <- rep("numeric", numberCols)
concrete_tbl <- read_excel(path = paste0(folder, filename), col_types = colTypes)

concrete_tbl <- concrete_tbl %>%
  rename(cement = starts_with("Cement")) %>%
  rename(blast_furnace_slag = starts_with("Blast")) %>%
  rename(fly_ash = starts_with("Fly Ash")) %>%
  rename(water = starts_with("Water")) %>%
  rename(superplasticizer = starts_with("Super")) %>%
  rename(coarse_aggregate = starts_with("Coarse")) %>%
  rename(fine_aggregate = starts_with("Fine")) %>%
  rename(age = starts_with("Age")) %>%
  rename(compressive_strength = starts_with("Concrete"))
```

### Initialize the Python environment

The ```reticulate``` library has been already loaded.  We want to use Python packages next so the following code activates a Python 3.8 environment set up through miniconda.
```{r}
use_condaenv("py3.8", required = TRUE)
py_config()
```
### Import Python libraries
```{python}
import pandas as pd
import numpy as np

#Pre-processing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
#Gaussian process model
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel, WhiteKernel

import sklearn.metrics as metrics
```

##Building the Gaussian Process Model

In general, the Sci-kit learn models require the independent (a.k.a. predictor) variables and dependent (a.k.a. target) variables to be in separate dataframes.  By convention, the predictors are in X and the target is in y. **Using the ```StandardScaler``` requires a conversion from a dataframe to a numpy array using ```.values```.**  Next, we split into train and test datasets.

```{python}
X = r.concrete_tbl.drop(['compressive_strength'], axis=1).values
y = r.concrete_tbl['compressive_strength'].values

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.4, random_state = 10)
```

Here, I add the centering and scaling of the predictors and target using ```StandardScaler```.  The target variable needs to be converted to a single column using ```.reshape(-1,1)```.

```{python}
scaler = StandardScaler()
target_scaler = StandardScaler()

X_train_scale = scaler.fit_transform(X_train)
y_train_scale = target_scaler.fit_transform(y_train.reshape(-1,1))
```

There are many different options for selecting the kernels however I found that combining the radial basis function (RBF) kernel with a constant to account for mean offset and a white kernel to account for noisy data seemed to be a successful approach for this type of dataset.  And by success, I mean a fit that converges to a GP model without further warnings and with a respectable R-squared.

```{python}
kernel = ConstantKernel() * RBF() + WhiteKernel()

gp_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer = 5)

gp_model.fit(X_train_scale, y_train_scale)

gp_model.kernel_
```

You need to reverse the scaling in order to compare with the original values and more easily assess the metrics.
```{python}
#Model Evaluation and error calculations
y_pred_tr_scale, y_pred_tr_std_scale = gp_model.predict(X_train_scale, return_std=True)
y_pred_tr = target_scaler.inverse_transform(y_pred_tr_scale.reshape(-1,1))

train_metrics = [["RSq", metrics.r2_score(y_train, y_pred_tr)], ["Adjusted RSq", 1 - (1-metrics.r2_score(y_train, y_pred_tr))*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)], ["MAE", metrics.mean_absolute_error(y_train, y_pred_tr)], ["MSE", metrics.mean_squared_error(y_train, y_pred_tr)], ["RMSE", np.sqrt(metrics.mean_squared_error(y_train, y_pred_tr))]]

train_metrics_df = pd.DataFrame(train_metrics, columns = ["metric", "value"])
print(train_metrics_df)
```
We can visualize the predicted vs. actual (measured) compressive strengths in the figure below.

```{r}
pred_train <- tibble(y_train = py$y_train, y_pred_tr = as.vector(py$y_pred_tr))

ggplot(data = pred_train, aes(x = y_train, y = y_pred_tr)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(title = "Gaussian Process Model: Predicted vs. Measured for Training Data",
       x = "Actual Compressive Strength (MPa)",
       y = "Predicted Compressive Strength (MPa)") +
  theme_light()
```

The distribution of model residuals should ideally be centered around 0 and normally distributed.  The residuals for the Gaussian Process Model are shown in the figure below.

```{r}
pred_train %>%
  mutate(resid_tr = y_train - y_pred_tr) %>%
  ggplot(aes(x = resid_tr)) +
    geom_histogram(aes(y = ..density..), fill="lightblue") +
    geom_density(color="darkblue") +
    geom_vline(aes(xintercept = mean(resid_tr)), linetype = "dashed") +
    labs(title = "Residual Error",
         x = "Compressive Strength") +
  theme_light()
```

The residuals are centered around zero and about evenly distributed between negative and positive deviations.  A few outliers are evident especially in the prediction beyond -20 MPa.  The model performance on the training data was deemed acceptable to proceed to evaluation of the test data.

## Evaluating the GP model predictions for the test data

You need to scale the test data before prediction using the same scaling used on the training dataset.
```{python}
X_test_scale = scaler.transform(X_test)
y_pred_te_scale, y_pred_te_std_scale = gp_model.predict(X_test_scale, return_std=True)
y_pred_te = target_scaler.inverse_transform(y_pred_te_scale.reshape(-1,1))
y_pred_te_std = y_pred_te_std_scale * target_scaler.scale_

tpred_gp = metrics.r2_score(y_test, y_pred_te)

test_metrics = [["Rsq", metrics.r2_score(y_test, y_pred_te)], ["Adjusted RSq", 1 - (1-metrics.r2_score(y_test, y_pred_te))*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)], ["MAE", metrics.mean_absolute_error(y_test, y_pred_te)], ["MSE", metrics.mean_squared_error(y_test, y_pred_te)], ["RMSE", np.sqrt(metrics.mean_squared_error(y_test, y_pred_te))]]

test_metrics_df = pd.DataFrame(test_metrics, columns = ["metric", "value"])
print(test_metrics_df)
```

The model performance was a bit worse for the testing data as compared to the training data.  I believe one reason is that cross-validation was not used and the model is overfitting the training data.  One of the advantages of the Gaussian Process model is the estimation of uncertainty in the prediction.  In the figure below, the predicted vs. measured compressive strengths for the test dataset are displayed along with error bars for +/- 1 standard deviation.

```{r}
pred_test <- tibble(y_test = py$y_test, y_pred_te = as.vector(py$y_pred_te), y_pred_te_std = py$y_pred_te_std)

ggplot(data = pred_test, aes(x = y_test, y = y_pred_te)) +
  geom_point() +
  geom_errorbar(aes(ymin = y_pred_te - y_pred_te_std, ymax = y_pred_te + y_pred_te_std)) +
  geom_smooth(method = "lm") +
  labs(title = "Gaussian Process Model: Predicted vs. Measured for Testing Data",
       x = "Actual Compressive Strength (MPa)",
       y = "Predicted Compressive Strength (MPa)") +
  theme_light()
```

## Summary
A Gaussian process model has been built for the concrete dataset.  The predictive performance of this model was lower than for random forest and xgboost models (GP R^2^ = 0.89 vs. RF R^2^ = 0.94).  The main advantage of the Gaussian Process model is the calculation of prediction error which can be very helpful in assessing confidence in future predictions.

:::{.callout-tip collapse="true"}
## Expand for Session Info
```{r}
#| warning: false
#| echo: false
library(sessioninfo)
# save the session info as an object
pkg_sesh <- session_info(pkgs = "attached")

# get the quarto version
quarto_version <- system("quarto --version", intern = TRUE)

# inject the quarto info
pkg_sesh$platform$quarto <- paste(
  system("quarto --version", intern = TRUE), 
  "@", 
  quarto::quarto_path()
  )

# print it out
pkg_sesh
```
:::